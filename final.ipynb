{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epoch , training loss is 230.50 , correct_number is 56109  accuracy is 0.935150. \n",
      "After 1 epoch , training loss is 88.17 , correct_number is 58295  accuracy is 0.971583. \n",
      "After 2 epoch , training loss is 61.50 , correct_number is 58789  accuracy is 0.979817. \n",
      "After 3 epoch , training loss is 47.45 , correct_number is 59058  accuracy is 0.984300. \n",
      "After 4 epoch , training loss is 35.46 , correct_number is 59294  accuracy is 0.988233. \n",
      "After 5 epoch , training loss is 30.74 , correct_number is 59400  accuracy is 0.990000. \n",
      "After 6 epoch , training loss is 25.21 , correct_number is 59496  accuracy is 0.991600. \n",
      "After 7 epoch , training loss is 20.62 , correct_number is 59617  accuracy is 0.993617. \n",
      "After 8 epoch , training loss is 16.71 , correct_number is 59676  accuracy is 0.994600. \n",
      "After 9 epoch , training loss is 15.05 , correct_number is 59704  accuracy is 0.995067. \n",
      "After 10 epoch , training loss is 12.08 , correct_number is 59781  accuracy is 0.996350. \n",
      "After 11 epoch , training loss is 11.22 , correct_number is 59769  accuracy is 0.996150. \n",
      "After 12 epoch , training loss is 9.20 , correct_number is 59830  accuracy is 0.997167. \n",
      "After 13 epoch , training loss is 9.74 , correct_number is 59807  accuracy is 0.996783. \n",
      "After 14 epoch , training loss is 8.00 , correct_number is 59863  accuracy is 0.997717. \n",
      "After 15 epoch , training loss is 7.73 , correct_number is 59850  accuracy is 0.997500. \n",
      "After 16 epoch , training loss is 7.52 , correct_number is 59855  accuracy is 0.997583. \n",
      "After 17 epoch , training loss is 6.19 , correct_number is 59895  accuracy is 0.998250. \n",
      "After 18 epoch , training loss is 4.80 , correct_number is 59918  accuracy is 0.998633. \n",
      "After 19 epoch , training loss is 5.37 , correct_number is 59911  accuracy is 0.998517. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Aabba\\lib\\site-packages\\ipykernel_launcher.py:97: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "B:\\Aabba\\lib\\site-packages\\ipykernel_launcher.py:98: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.058028,ACC: 0.983500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from  torch.autograd import *\n",
    "from  torch import nn,optim\n",
    "from  torch.utils.data import DataLoader\n",
    "from  torchvision import datasets,transforms\n",
    " \n",
    "class simpleNet(nn.Module):\n",
    "    def __init__(self,in_dim,n_hidden_1,n_hidden_2,out_dim):\n",
    "        super(simpleNet,self).__init__()\n",
    "        self.layer1=nn.Linear(in_dim,n_hidden_1)\n",
    "        self.layer2=nn.Linear(n_hidden_1,n_hidden_2)\n",
    "        self.layer3=nn.Linear(n_hidden_2,out_dim)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    " \n",
    " \n",
    "class Activation_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    " \n",
    "class Batch_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.BatchNorm1d(n_hidden_1),nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.BatchNorm1d(n_hidden_2),nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    " \n",
    "batch_size=64\n",
    "learning_rate=1e-1\n",
    "num_epoches=20\n",
    " \n",
    "data_tf=transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5],[0.5])])\n",
    "train_dataset=datasets.MNIST(root='./data',train=True,transform=data_tf,download=True)\n",
    "test_dataset=datasets.MNIST(root=\"./data\",train=False,transform=data_tf)\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    " \n",
    "model=Batch_Net(28*28,300,100,10)\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=learning_rate)\n",
    " \n",
    "for epoch in range(num_epoches):\n",
    "    loss_sum, cort_num_sum,acc = 0.0, 0,0\n",
    "    for data in train_loader:\n",
    "        img,label=data\n",
    "        img=img.view(img.size(0),-1)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(img).cuda()\n",
    "            target = Variable(label).cuda()\n",
    "        else:\n",
    "            inputs = Variable(img)\n",
    "            target = Variable(label)\n",
    "        output =model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "        _, pred = output.data.max(1)\n",
    "        num_correct = pred.eq(target).sum()\n",
    "        cort_num_sum += num_correct\n",
    "    acc=cort_num_sum.float()/len(train_dataset)\n",
    "    print( \"After %d epoch , training loss is %.2f , correct_number is %d  accuracy is %.6f. \"%(epoch,loss_sum,cort_num_sum,acc))\n",
    " \n",
    " \n",
    "model.eval()\n",
    "eval_loss=0\n",
    "eval_acc=0\n",
    "for data in test_loader:\n",
    "    img ,label =data\n",
    "    img=img.view(img.size(0),-1)\n",
    "    if torch.cuda.is_available():\n",
    "        img=Variable(img,volatile=True)\n",
    "        label=Variable(label,volatile=True)\n",
    "    else:\n",
    "        img = Variable(img, volatile=True)\n",
    "        label = Variable(label, volatile=True)\n",
    "    out=model(img)\n",
    "    loss=criterion(out,label)\n",
    "    eval_loss+=loss.data*label.size(0)\n",
    "    _,pred=out.data.max(1)\n",
    "    num_correct=pred.eq(label).sum()\n",
    "    eval_acc+=num_correct.data\n",
    "print('Test loss: {:.6f},ACC: {:.6f}'.format(eval_loss.float()/(len(test_dataset)),eval_acc.float()/(len(test_dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see clearly the pictures we use in dataset, we can simply run the codes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import struct\n",
    " \n",
    "from PIL import Image\n",
    "import os\n",
    " \n",
    "data_file = './data/raw/train-images-idx3-ubyte'\n",
    "# It's 47040016B, but we should set to 47040000B\n",
    "data_file_size = 47040016\n",
    "data_file_size = str(data_file_size - 16) + 'B'\n",
    " \n",
    "data_buf = open(data_file, 'rb').read()\n",
    " \n",
    "magic, numImages, numRows, numColumns = struct.unpack_from(\n",
    "    '>IIII', data_buf, 0)\n",
    "datas = struct.unpack_from(\n",
    "    '>' + data_file_size, data_buf, struct.calcsize('>IIII'))\n",
    "datas = np.array(datas).astype(np.uint8).reshape(\n",
    "    numImages, 1, numRows, numColumns)\n",
    " \n",
    "label_file = './data/raw/train-labels-idx1-ubyte'\n",
    " \n",
    "# It's 60008B, but we should set to 60000B\n",
    "label_file_size = 60008\n",
    "label_file_size = str(label_file_size - 8) + 'B'\n",
    " \n",
    "label_buf = open(label_file, 'rb').read()\n",
    " \n",
    "magic, numLabels = struct.unpack_from('>II', label_buf, 0)\n",
    "labels = struct.unpack_from(\n",
    "    '>' + label_file_size, label_buf, struct.calcsize('>II'))\n",
    "labels = np.array(labels).astype(np.int64)\n",
    " \n",
    "datas_root = 'mnist_train'\n",
    "if not os.path.exists(datas_root):\n",
    "    os.mkdir(datas_root)\n",
    " \n",
    "for i in range(10):\n",
    "    file_name = datas_root + os.sep + str(i)\n",
    "    if not os.path.exists(file_name):\n",
    "        os.mkdir(file_name)\n",
    " \n",
    "for ii in range(numLabels):\n",
    "    img = Image.fromarray(datas[ii, 0, 0:28, 0:28])\n",
    "    label = labels[ii]\n",
    "    file_name = datas_root + os.sep + str(label) + os.sep + \\\n",
    "        'mnist_train_' + str(ii) + '.png'\n",
    "    img.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying different learning rate, the MLP model gets a good result of 0.058028 loss and 0.983500 accuracy, which is quite efficient on recognizing single handwritten number. The next step I'd like is to enrich this algorithm making it possible to split numbers and letters in sentences and articles, and so finally to recognize the whole handwritten text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
